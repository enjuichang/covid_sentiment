{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "## Neural Model\nThis is the code for the training the neural models.\n\n### Structure\n- Package Setup\n- Reorganize the data\n- Config Setup\n- Model Training\n- Verifidcation",
   "metadata": {
    "tags": [],
    "cell_id": "00000-26e23d31-a20e-48d2-9de2-2302c07ebf74",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Setup\nHere, I setup the packages and imported the data needed for model training.\n\n**Downloaded Packages**\n1. SpaCy English library\n2. SpaCy English Roberta-based library\n3. SpaCy Transformer\n\n**Imported Packages**\n1. Pandas\n2. SpaCy\n3. Scikit-learn\n4. re\n5. tqrm",
   "metadata": {
    "tags": [],
    "cell_id": "00001-d66f9fca-2e62-4fd6-ac81-059b63a63de8",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00000-3c091abe-1b72-42dc-8400-711bf752cc9f",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "32c9909a",
    "execution_start": 1635858030954,
    "execution_millis": 37755,
    "deepnote_cell_type": "code"
   },
   "source": "# Installation of packages and pipelines\n# Import spaCy, load model\n!pip install spaCy \n!pip install spacy[transformers]\n!python -m spacy download en_core_web_sm\n!python -m spacy download en_core_web_trf\n",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Requirement already satisfied: spaCy in /shared-libs/python3.7/py/lib/python3.7/site-packages (3.1.3)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spaCy) (2.0.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spaCy) (3.0.8)\nRequirement already satisfied: thinc<8.1.0,>=8.0.9 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spaCy) (8.0.10)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spaCy) (2.0.6)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spaCy) (1.0.5)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spaCy) (2.26.0)\nRequirement already satisfied: jinja2 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from spaCy) (3.0.2)\nRequirement already satisfied: numpy>=1.15.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spaCy) (1.19.5)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spaCy) (4.62.3)\nRequirement already satisfied: pathy>=0.3.5 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spaCy) (0.6.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spaCy) (1.8.2)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spaCy) (0.7.4)\nRequirement already satisfied: typer<0.5.0,>=0.3.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spaCy) (0.4.0)\nRequirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from spaCy) (3.10.0.2)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spaCy) (3.0.5)\nRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spaCy) (0.8.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spaCy) (2.4.1)\nRequirement already satisfied: packaging>=20.0 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from spaCy) (21.0)\nRequirement already satisfied: setuptools in /root/venv/lib/python3.7/site-packages (from spaCy) (58.1.0)\nRequirement already satisfied: zipp>=0.5 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spaCy) (3.6.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from packaging>=20.0->spaCy) (2.4.7)\nRequirement already satisfied: smart-open<6.0.0,>=5.0.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from pathy>=0.3.5->spaCy) (5.2.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spaCy) (1.26.7)\nRequirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spaCy) (2021.10.8)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spaCy) (2.0.7)\nRequirement already satisfied: idna<4,>=2.5 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spaCy) (3.3)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spaCy) (8.0.3)\nRequirement already satisfied: importlib-metadata in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spaCy) (4.8.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from jinja2->spaCy) (2.0.1)\n\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: spacy[transformers] in /shared-libs/python3.7/py/lib/python3.7/site-packages (3.1.3)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy[transformers]) (3.0.8)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy[transformers]) (2.26.0)\nRequirement already satisfied: numpy>=1.15.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy[transformers]) (1.19.5)\nRequirement already satisfied: typer<0.5.0,>=0.3.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy[transformers]) (0.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy[transformers]) (4.62.3)\nRequirement already satisfied: pathy>=0.3.5 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy[transformers]) (0.6.0)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy[transformers]) (3.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy[transformers]) (1.0.5)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy[transformers]) (0.7.4)\nRequirement already satisfied: srsly<3.0.0,>=2.4.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy[transformers]) (2.4.1)\nRequirement already satisfied: setuptools in /root/venv/lib/python3.7/site-packages (from spacy[transformers]) (58.1.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy[transformers]) (1.8.2)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy[transformers]) (2.0.6)\nRequirement already satisfied: jinja2 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from spacy[transformers]) (3.0.2)\nRequirement already satisfied: packaging>=20.0 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from spacy[transformers]) (21.0)\nRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy[transformers]) (0.8.2)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy[transformers]) (2.0.5)\nRequirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from spacy[transformers]) (3.10.0.2)\nRequirement already satisfied: thinc<8.1.0,>=8.0.9 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy[transformers]) (8.0.10)\nCollecting spacy-transformers<1.1.0,>=1.0.1\n  Downloading spacy_transformers-1.0.6-py2.py3-none-any.whl (42 kB)\n\u001b[K     |████████████████████████████████| 42 kB 2.2 MB/s \n\u001b[?25hRequirement already satisfied: zipp>=0.5 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy[transformers]) (3.6.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from packaging>=20.0->spacy[transformers]) (2.4.7)\nRequirement already satisfied: smart-open<6.0.0,>=5.0.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from pathy>=0.3.5->spacy[transformers]) (5.2.1)\nRequirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]) (2021.10.8)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]) (2.0.7)\nRequirement already satisfied: idna<4,>=2.5 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]) (1.26.7)\nCollecting spacy-alignments<1.0.0,>=0.7.2\n  Downloading spacy_alignments-0.8.3-cp37-cp37m-manylinux2014_x86_64.whl (998 kB)\n\u001b[K     |████████████████████████████████| 998 kB 57.0 MB/s \n\u001b[?25hCollecting transformers<4.10.0,>=3.4.0\n  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n\u001b[K     |████████████████████████████████| 2.6 MB 102.2 MB/s \n\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy-transformers<1.1.0,>=1.0.1->spacy[transformers]) (1.9.1)\nRequirement already satisfied: filelock in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from transformers<4.10.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.1->spacy[transformers]) (3.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from transformers<4.10.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.1->spacy[transformers]) (2021.10.8)\nCollecting huggingface-hub==0.0.12\n  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\nCollecting sacremoses\n  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n\u001b[K     |████████████████████████████████| 895 kB 93.5 MB/s \n\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n\u001b[K     |████████████████████████████████| 3.3 MB 79.2 MB/s \n\u001b[?25hRequirement already satisfied: importlib-metadata in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from transformers<4.10.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.1->spacy[transformers]) (4.8.1)\nRequirement already satisfied: pyyaml>=5.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from transformers<4.10.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.1->spacy[transformers]) (5.4.1)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy[transformers]) (8.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from jinja2->spacy[transformers]) (2.0.1)\nRequirement already satisfied: joblib in /shared-libs/python3.7/py/lib/python3.7/site-packages (from sacremoses->transformers<4.10.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.1->spacy[transformers]) (1.1.0)\nRequirement already satisfied: six in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from sacremoses->transformers<4.10.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.1->spacy[transformers]) (1.16.0)\nInstalling collected packages: tokenizers, sacremoses, huggingface-hub, transformers, spacy-alignments, spacy-transformers\nSuccessfully installed huggingface-hub-0.0.12 sacremoses-0.0.46 spacy-alignments-0.8.3 spacy-transformers-1.0.6 tokenizers-0.10.3 transformers-4.9.2\n\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n2021-11-02 13:00:40.625212: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2021-11-02 13:00:40.625248: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\nCollecting en-core-web-sm==3.1.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n\u001b[K     |████████████████████████████████| 13.6 MB 21.3 MB/s \n\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from en-core-web-sm==3.1.0) (3.1.3)\nRequirement already satisfied: pathy>=0.3.5 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.0)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.5)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.6)\nRequirement already satisfied: packaging>=20.0 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (21.0)\nRequirement already satisfied: srsly<3.0.0,>=2.4.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.1)\nRequirement already satisfied: setuptools in /root/venv/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (58.1.0)\nRequirement already satisfied: typer<0.5.0,>=0.3.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.0)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.4)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.5)\nRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8.2)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.5)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.26.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.62.3)\nRequirement already satisfied: jinja2 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.2)\nRequirement already satisfied: thinc<8.1.0,>=8.0.9 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.10)\nRequirement already satisfied: numpy>=1.15.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.19.5)\nRequirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.10.0.2)\nRequirement already satisfied: zipp>=0.5 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.6.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.7)\nRequirement already satisfied: smart-open<6.0.0,>=5.0.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.2.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.26.7)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.7)\nRequirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2021.10.8)\nRequirement already satisfied: idna<4,>=2.5 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.3)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.3)\nRequirement already satisfied: importlib-metadata in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.8.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.1)\nInstalling collected packages: en-core-web-sm\nSuccessfully installed en-core-web-sm-3.1.0\n\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n2021-11-02 13:00:49.418087: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2021-11-02 13:00:49.418126: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\nCollecting en-core-web-trf==3.1.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.1.0/en_core_web_trf-3.1.0-py3-none-any.whl (460.2 MB)\n\u001b[K     |████████████████████████████████| 460.2 MB 7.4 kB/s \n\u001b[?25hRequirement already satisfied: spacy-transformers<1.1.0,>=1.0.3 in /root/venv/lib/python3.7/site-packages (from en-core-web-trf==3.1.0) (1.0.6)\nRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from en-core-web-trf==3.1.0) (3.1.3)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (0.7.4)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (1.0.5)\nRequirement already satisfied: setuptools in /root/venv/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (58.1.0)\nRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (0.8.2)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (3.0.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (3.0.8)\nRequirement already satisfied: srsly<3.0.0,>=2.4.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (2.4.1)\nRequirement already satisfied: packaging>=20.0 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (21.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (1.8.2)\nRequirement already satisfied: jinja2 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (3.0.2)\nRequirement already satisfied: thinc<8.1.0,>=8.0.9 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (8.0.10)\nRequirement already satisfied: typer<0.5.0,>=0.3.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (0.4.0)\nRequirement already satisfied: pathy>=0.3.5 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (0.6.0)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (2.26.0)\nRequirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (3.10.0.2)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (4.62.3)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (2.0.5)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (2.0.6)\nRequirement already satisfied: numpy>=1.15.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (1.19.5)\nRequirement already satisfied: zipp>=0.5 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (3.6.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (2.4.7)\nRequirement already satisfied: smart-open<6.0.0,>=5.0.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (5.2.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (1.26.7)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (2.0.7)\nRequirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (2021.10.8)\nRequirement already satisfied: idna<4,>=2.5 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (3.3)\nRequirement already satisfied: transformers<4.10.0,>=3.4.0 in /root/venv/lib/python3.7/site-packages (from spacy-transformers<1.1.0,>=1.0.3->en-core-web-trf==3.1.0) (4.9.2)\nRequirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /root/venv/lib/python3.7/site-packages (from spacy-transformers<1.1.0,>=1.0.3->en-core-web-trf==3.1.0) (0.8.3)\nRequirement already satisfied: torch>=1.5.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy-transformers<1.1.0,>=1.0.3->en-core-web-trf==3.1.0) (1.9.1)\nRequirement already satisfied: regex!=2019.12.17 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from transformers<4.10.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.3->en-core-web-trf==3.1.0) (2021.10.8)\nRequirement already satisfied: huggingface-hub==0.0.12 in /root/venv/lib/python3.7/site-packages (from transformers<4.10.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.3->en-core-web-trf==3.1.0) (0.0.12)\nRequirement already satisfied: importlib-metadata in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from transformers<4.10.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.3->en-core-web-trf==3.1.0) (4.8.1)\nRequirement already satisfied: filelock in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from transformers<4.10.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.3->en-core-web-trf==3.1.0) (3.3.0)\nRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /root/venv/lib/python3.7/site-packages (from transformers<4.10.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.3->en-core-web-trf==3.1.0) (0.10.3)\nRequirement already satisfied: pyyaml>=5.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from transformers<4.10.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.3->en-core-web-trf==3.1.0) (5.4.1)\nRequirement already satisfied: sacremoses in /root/venv/lib/python3.7/site-packages (from transformers<4.10.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.3->en-core-web-trf==3.1.0) (0.0.46)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (8.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (2.0.1)\nRequirement already satisfied: six in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from sacremoses->transformers<4.10.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.3->en-core-web-trf==3.1.0) (1.16.0)\nRequirement already satisfied: joblib in /shared-libs/python3.7/py/lib/python3.7/site-packages (from sacremoses->transformers<4.10.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.3->en-core-web-trf==3.1.0) (1.1.0)\nInstalling collected packages: en-core-web-trf\nSuccessfully installed en-core-web-trf-3.1.0\n\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_trf')\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00002-f5e4b070-fa4e-4427-b310-05085ab2dd09",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6165965a",
    "execution_start": 1635858068713,
    "execution_millis": 3863,
    "deepnote_cell_type": "code"
   },
   "source": "# Import packages\nimport spacy\nimport pandas as pd\nimport re\nfrom spacy.tokens import DocBin\nfrom tqdm import tqdm",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "I imported the data here.",
   "metadata": {
    "tags": [],
    "cell_id": "00004-d8b4a127-20ac-4e9d-8d07-6dba96208bb0",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00003-51c1b8f2-8900-4b74-81d1-291892f9206c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "162d9b1c",
    "execution_start": 1635858072581,
    "execution_millis": 214,
    "deepnote_cell_type": "code"
   },
   "source": "# Import dataset and pandas\nraw_trainDF = pd.read_csv(\"/work/data/coronavirus_tweet_raw/Corona_NLP_train.csv\")\nraw_testDF = pd.read_csv(\"/work/data/coronavirus_tweet_raw/Corona_NLP_test.csv\")\nraw_trainDF.head()",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 3,
     "data": {
      "application/vnd.deepnote.dataframe.v2+json": {
       "row_count": 5,
       "column_count": 6,
       "columns": [
        {
         "name": "UserName",
         "dtype": "int64",
         "stats": {
          "unique_count": 5,
          "nan_count": 0,
          "min": "3799",
          "max": "3803",
          "histogram": [
           {
            "bin_start": 3799,
            "bin_end": 3799.4,
            "count": 1
           },
           {
            "bin_start": 3799.4,
            "bin_end": 3799.8,
            "count": 0
           },
           {
            "bin_start": 3799.8,
            "bin_end": 3800.2,
            "count": 1
           },
           {
            "bin_start": 3800.2,
            "bin_end": 3800.6,
            "count": 0
           },
           {
            "bin_start": 3800.6,
            "bin_end": 3801,
            "count": 0
           },
           {
            "bin_start": 3801,
            "bin_end": 3801.4,
            "count": 1
           },
           {
            "bin_start": 3801.4,
            "bin_end": 3801.8,
            "count": 0
           },
           {
            "bin_start": 3801.8,
            "bin_end": 3802.2,
            "count": 1
           },
           {
            "bin_start": 3802.2,
            "bin_end": 3802.6,
            "count": 0
           },
           {
            "bin_start": 3802.6,
            "bin_end": 3803,
            "count": 1
           }
          ]
         }
        },
        {
         "name": "ScreenName",
         "dtype": "int64",
         "stats": {
          "unique_count": 5,
          "nan_count": 0,
          "min": "48751",
          "max": "48755",
          "histogram": [
           {
            "bin_start": 48751,
            "bin_end": 48751.4,
            "count": 1
           },
           {
            "bin_start": 48751.4,
            "bin_end": 48751.8,
            "count": 0
           },
           {
            "bin_start": 48751.8,
            "bin_end": 48752.2,
            "count": 1
           },
           {
            "bin_start": 48752.2,
            "bin_end": 48752.6,
            "count": 0
           },
           {
            "bin_start": 48752.6,
            "bin_end": 48753,
            "count": 0
           },
           {
            "bin_start": 48753,
            "bin_end": 48753.4,
            "count": 1
           },
           {
            "bin_start": 48753.4,
            "bin_end": 48753.8,
            "count": 0
           },
           {
            "bin_start": 48753.8,
            "bin_end": 48754.2,
            "count": 1
           },
           {
            "bin_start": 48754.2,
            "bin_end": 48754.6,
            "count": 0
           },
           {
            "bin_start": 48754.6,
            "bin_end": 48755,
            "count": 1
           }
          ]
         }
        },
        {
         "name": "Location",
         "dtype": "object",
         "stats": {
          "unique_count": 3,
          "nan_count": 2,
          "categories": [
           {
            "name": "London",
            "count": 1
           },
           {
            "name": "2 others",
            "count": 2
           },
           {
            "name": "Missing",
            "count": 2
           }
          ]
         }
        },
        {
         "name": "TweetAt",
         "dtype": "object",
         "stats": {
          "unique_count": 1,
          "nan_count": 0,
          "categories": [
           {
            "name": "16-03-2020",
            "count": 5
           }
          ]
         }
        },
        {
         "name": "OriginalTweet",
         "dtype": "object",
         "stats": {
          "unique_count": 5,
          "nan_count": 0,
          "categories": [
           {
            "name": "@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/iFz9FAn2Pa and https://t.co/xX6ghGFzCC and https://t.co/I2NlzdxNo8",
            "count": 1
           },
           {
            "name": "advice Talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist GP set up online shopping accounts if poss adequate supplies of regular meds but not over order",
            "count": 1
           },
           {
            "name": "3 others",
            "count": 3
           }
          ]
         }
        },
        {
         "name": "Sentiment",
         "dtype": "object",
         "stats": {
          "unique_count": 3,
          "nan_count": 0,
          "categories": [
           {
            "name": "Positive",
            "count": 3
           },
           {
            "name": "Neutral",
            "count": 1
           },
           {
            "name": "Extremely Negative",
            "count": 1
           }
          ]
         }
        },
        {
         "name": "_deepnote_index_column",
         "dtype": "int64"
        }
       ],
       "rows_top": [
        {
         "UserName": 3799,
         "ScreenName": 48751,
         "Location": "London",
         "TweetAt": "16-03-2020",
         "OriginalTweet": "@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/iFz9FAn2Pa and https://t.co/xX6ghGFzCC and https://t.c…",
         "Sentiment": "Neutral",
         "_deepnote_index_column": 0
        },
        {
         "UserName": 3800,
         "ScreenName": 48752,
         "Location": "UK",
         "TweetAt": "16-03-2020",
         "OriginalTweet": "advice Talk to your neighbours family to exchange phone numbers create contact list with phone numb…",
         "Sentiment": "Positive",
         "_deepnote_index_column": 1
        },
        {
         "UserName": 3801,
         "ScreenName": 48753,
         "Location": "Vagabonds",
         "TweetAt": "16-03-2020",
         "OriginalTweet": "Coronavirus Australia: Woolworths to give elderly, disabled dedicated shopping hours amid COVID-19 …",
         "Sentiment": "Positive",
         "_deepnote_index_column": 2
        },
        {
         "UserName": 3802,
         "ScreenName": 48754,
         "Location": "nan",
         "TweetAt": "16-03-2020",
         "OriginalTweet": "My food stock is not the only one which is empty...\r\r\n\r\r\nPLEASE, don't panic, THERE WILL BE ENOUGH …",
         "Sentiment": "Positive",
         "_deepnote_index_column": 3
        },
        {
         "UserName": 3803,
         "ScreenName": 48755,
         "Location": "nan",
         "TweetAt": "16-03-2020",
         "OriginalTweet": "Me, ready to go at supermarket during the #COVID19 outbreak.\r\r\n\r\r\nNot because I'm paranoid, but bec…",
         "Sentiment": "Extremely Negative",
         "_deepnote_index_column": 4
        }
       ],
       "rows_bottom": null
      },
      "text/plain": "   UserName  ScreenName   Location     TweetAt  \\\n0      3799       48751     London  16-03-2020   \n1      3800       48752         UK  16-03-2020   \n2      3801       48753  Vagabonds  16-03-2020   \n3      3802       48754        NaN  16-03-2020   \n4      3803       48755        NaN  16-03-2020   \n\n                                       OriginalTweet           Sentiment  \n0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n1  advice Talk to your neighbours family to excha...            Positive  \n2  Coronavirus Australia: Woolworths to give elde...            Positive  \n3  My food stock is not the only one which is emp...            Positive  \n4  Me, ready to go at supermarket during the #COV...  Extremely Negative  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserName</th>\n      <th>ScreenName</th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3799</td>\n      <td>48751</td>\n      <td>London</td>\n      <td>16-03-2020</td>\n      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3800</td>\n      <td>48752</td>\n      <td>UK</td>\n      <td>16-03-2020</td>\n      <td>advice Talk to your neighbours family to excha...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3801</td>\n      <td>48753</td>\n      <td>Vagabonds</td>\n      <td>16-03-2020</td>\n      <td>Coronavirus Australia: Woolworths to give elde...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3802</td>\n      <td>48754</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>My food stock is not the only one which is emp...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3803</td>\n      <td>48755</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>Me, ready to go at supermarket during the #COV...</td>\n      <td>Extremely Negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00003-bdbae09b-0008-41d5-bba7-7ac199683b6b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "1734b6f0",
    "execution_start": 1635858072796,
    "execution_millis": 2,
    "deepnote_cell_type": "code"
   },
   "source": "# Copy the values of the data for further uses\ntrainDF = raw_trainDF\ntestDF = raw_testDF",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Reorganize the data\nDue to the observation during the EDA process, I decided to concatenate the dataset and resplit them.",
   "metadata": {
    "tags": [],
    "cell_id": "00005-e3f66c0c-1cc3-42b2-ad18-aeae2136dfae",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00005-e46ad648-9378-4f62-ad84-9a8473ded0b5",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "aab1244e",
    "execution_start": 1635858072800,
    "execution_millis": 543,
    "deepnote_cell_type": "code"
   },
   "source": "# Train test split\nfrom sklearn.model_selection import train_test_split\n\n# Concat the two datasets and split them\nallDF = pd.concat((trainDF, testDF), ignore_index=True)\n\n# Sample dataset due to the large size\nallDF = allDF.sample(frac=0.5).reset_index(drop=True)\n\n# Split the train, test, validation set\ntrainDF, testDF = train_test_split(allDF, test_size = 0.2)\ntestDF, validDF = train_test_split(testDF, test_size = 0.2)\n\n# Print values\nprint(\"Train:\",len(trainDF), \"Test:\", len(testDF),\"Valid:\", len(validDF))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Train: 17982 Test: 3596 Valid: 900\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Preprocess the data\n\nI then preprocess the data by removing urls, conduct one-hot encoding for the categories, and add the data into SpaCy pipelines. Finally, I saved the data into binary `.spacy` for training. In addition, I separated the pretraining with just standard English pipeline and RoBERTa-based pipeline.",
   "metadata": {
    "tags": [],
    "cell_id": "00009-c9225b40-c7e0-4964-9bbc-02cea72bc5db",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "![Preprocess Image](../images/preprocess_nn.png)",
   "metadata": {
    "tags": [],
    "cell_id": "00010-c85f4ba2-82b3-49e0-8127-3bb4f7997948",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00002-866ffbd9-556b-46db-864d-13b591162eb6",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9bf797bf",
    "execution_start": 1635858073345,
    "execution_millis": 1,
    "allow_embed": "code",
    "deepnote_cell_type": "code"
   },
   "source": "def remove_url(text): \n    '''\n    Remove urls from text.\n    ---\n    Input:\n    text (str): a sentence\n\n    Output:\n    parsed_text (str): text that has url removed\n    '''\n\n    # Use regrex to parse urls from the text\n    parsed_text = re.sub(r\"\\S*https?:\\S*\", \"\", text, flags=re.MULTILINE)\n    return parsed_text\n\ndef preprocess(df, embed):\n    '''\n    Preprocess the dataframe into spacy pipeline for later classification\n    ---\n    Input:\n    df (DataFrame): Pandas dataframe containing the raw text and outputs.\n    embed (str): Name of pipeline embedding used\n\n    Output:\n    df (DataFrame): Preprocessed input dataframe\n    docs (doc): SpaCy doc object that stores text data along with classification\n    '''\n\n    # Remove urls from text\n    df.OriginalTweet = df.OriginalTweet.apply(remove_url)\n\n    # Store the data into tuples\n    data = tuple(zip(df.OriginalTweet.tolist(), df.Sentiment.tolist())) \n    \n    # Load English library from SpaCy\n    nlp=spacy.load(embed)\n    print(data[0])\n\n    # Storage for docs\n    docs = []\n\n    # One-hot encoding for the classifications\n    for doc, label in tqdm(nlp.pipe(data, as_tuples=True), total = len(data)):\n        \n        if label=='Extremely Positive':\n            doc.cats['extremely_positive'] = 1\n            doc.cats['extremely_negative'] = 0\n            doc.cats['positive'] = 0\n            doc.cats['negative'] = 0\n            doc.cats['neutral']  = 0\n        elif label=='Positive':\n            doc.cats['extremely_positive'] = 0\n            doc.cats['extremely_negative'] = 1\n            doc.cats['positive'] = 0\n            doc.cats['negative'] = 0\n            doc.cats['neutral']  = 0\n        elif label=='Neutral':\n            doc.cats['extremely_positive'] = 0\n            doc.cats['extremely_negative'] = 0\n            doc.cats['positive'] = 0\n            doc.cats['negative'] = 0\n            doc.cats['neutral']  = 1\n        elif label=='Negative':\n            doc.cats['extremely_positive'] = 0\n            doc.cats['extremely_negative'] = 0\n            doc.cats['positive'] = 0\n            doc.cats['negative'] = 1\n            doc.cats['neutral']  = 0\n        else:\n            doc.cats['extremely_positive'] = 0\n            doc.cats['extremely_negative'] = 1\n            doc.cats['positive'] = 0\n            doc.cats['negative'] = 0\n            doc.cats['neutral']  = 0\n        # print(doc.cats)\n        \n        docs.append(doc)\n    return df, docs\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Config setup\n\nI setup the training config using SpaCy's [quickstart function](https://spacy.io/usage/training#quickstart). This creates a `base_config.cfg` that can be filled into `config.cfg`. This `config` file can then be used to train the model using command line operations. The setup for the quickstart function is shown in the image below.",
   "metadata": {
    "tags": [],
    "cell_id": "00012-97285783-fbfc-470d-afb3-74d457c0a855",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "![config_setup](../images/config_setup.png)",
   "metadata": {
    "tags": [],
    "cell_id": "00013-71f8fb1e-8669-44c3-9572-468d2be998bf",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00010-649bbc18-2053-47d5-a689-838939ad2569",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ff8f9ebb",
    "execution_start": 1635724016177,
    "execution_millis": 9375,
    "allow_embed": "code_output",
    "deepnote_cell_type": "code"
   },
   "source": "# Initialize config files from base_config\n!python -m spacy init fill-config ../config/base_config.cfg ../config/config.cfg ",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "2021-10-31 23:46:58.031841: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2021-10-31 23:46:58.031884: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n\u001b[38;5;2m✔ Saved config\u001b[0m\n../config/config.cfg\nYou can now add your data and train your pipeline:\npython -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00016-8d9aae97-6594-498a-84ce-e5e3a9215870",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6dbb2d4e",
    "execution_start": 1635724025573,
    "execution_millis": 5086,
    "deepnote_cell_type": "code"
   },
   "source": "# Debug config\n!python -m spacy debug data ../config/config.cfg",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "2021-10-31 23:47:07.092715: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2021-10-31 23:47:07.092753: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n\u001b[1m\n============================ Data file validation ============================\u001b[0m\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/spacy/__main__.py\", line 4, in <module>\n    setup_cli()\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/spacy/cli/_util.py\", line 69, in setup_cli\n    command(prog_name=COMMAND)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/click/core.py\", line 1128, in __call__\n    return self.main(*args, **kwargs)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/click/core.py\", line 1053, in main\n    rv = self.invoke(ctx)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/click/core.py\", line 1659, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/click/core.py\", line 1659, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/click/core.py\", line 1395, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/click/core.py\", line 754, in invoke\n    return __callback(*args, **kwargs)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/typer/main.py\", line 500, in wrapper\n    return callback(**use_params)  # type: ignore\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/spacy/cli/debug_data.py\", line 71, in debug_data_cli\n    silent=False,\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/spacy/cli/debug_data.py\", line 103, in debug_data\n    train_corpus, dev_corpus = resolve_dot_names(config, dot_names)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/spacy/util.py\", line 500, in resolve_dot_names\n    result = registry.resolve(config[section])\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/thinc/config.py\", line 730, in resolve\n    config, schema=schema, overrides=overrides, validate=validate, resolve=True\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/thinc/config.py\", line 779, in _make\n    config, schema, validate=validate, overrides=overrides, resolve=resolve\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/thinc/config.py\", line 850, in _fill\n    getter_result = getter(*args, **kwargs)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/spacy/training/corpus.py\", line 31, in create_docbin_reader\n    raise ValueError(Errors.E913)\nValueError: [E913] Corpus path can't be None. Maybe you forgot to define it in your config.cfg or override it on the CLI?\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## SpaCy's Standard Model\nI first train the model with normal English pipeline from spaCy.",
   "metadata": {
    "tags": [],
    "cell_id": "00011-3df34364-3cfe-4853-8104-a8d925abe713",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00009-605760bf-f627-4873-a2c6-22e477c4afa1",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c72c9fee",
    "execution_start": 1635723925928,
    "execution_millis": 90229,
    "allow_embed": "code",
    "deepnote_cell_type": "code"
   },
   "source": "# Covert the train and test dataframes to .spacy files for training\n\n# Preprocess the dataframes for train data\ntrain_data, train_docs = preprocess(trainDF,\"en_core_web_sm\")\n# Save data and docs in a binary file to disc\ndoc_bin = DocBin(docs=train_docs)\ndoc_bin.to_disk(\"/work/data/spacy_data/textcat_train.spacy\")\n\n# Preprocess the dataframes for test data\ntest_data, test_docs = preprocess(testDF,\"en_core_web_sm\")\n# Save data and docs in a binary file to disc\ndoc_bin = DocBin(docs=test_docs)\ndoc_bin.to_disk(\"/work/data/spacy_data/textcat_valid.spacy\")",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "('I work in a supermarket. I understand why social distancing &amp; self isolating is so important right now. However. I\\x92m still going into work &amp; risking my own exposure ? HOW the hell do I help myself &amp; others ??! Confused #Covid_19', 'Extremely Negative')\n100%|██████████| 17982/17982 [01:01<00:00, 290.76it/s]\n('Dampf, store manager of the Paramus @StewLeonards: \"We don\\x92t have a lot of paper goods ... soap ... cleaning supplies. That\\x92s not what our niche is. We\\x92re a fresh food market: 80% of our items are fresh food. Only 20% is grocery.\" / #COVID19 #coronavirus ', 'Positive')\n100%|██████████| 3596/3596 [00:13<00:00, 263.99it/s]\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Model training\n\nI first verify the `.spacy` files before running the command line operation for training the model. The model is an ensemble of a tok2vec model that uses attention under the transformer architecture combined with a linear bag-of-words model. I trained the model for 11 epochs using accuracy as the loss function and `adam` as the optimizer.",
   "metadata": {
    "tags": [],
    "cell_id": "00016-5f3273ad-079a-4243-9716-763e6e3760e8",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00016-aa33cfa6-8a07-45fc-9c58-02f5648f81c6",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ab38c155",
    "execution_start": 1635724030665,
    "execution_millis": 8144,
    "deepnote_cell_type": "code"
   },
   "source": "# View the entities in the train and test docs\ntrain_loc = \"/work/data/spacy_data/textcat_train.spacy\"\ndev_loc = \"/work/data/spacy_data/textcat_valid.spacy\"\n\n# Load library and train data\nnlp = spacy.load('en_core_web_sm')\ndoc_bin = DocBin().from_disk(train_loc)\ndocs = list(doc_bin.get_docs(nlp.vocab))\nentities = 0\n\n# Iterate through the docs\nfor doc in docs:\n    entities += len(doc.ents)\nprint(f\"TRAIN docs: {len(docs)} with {entities} entities\")\n\n# Load library and test data\ndoc_bin = DocBin().from_disk(dev_loc)\ndocs = list(doc_bin.get_docs(nlp.vocab))\nentities = 0\n\n# Iterate through the docs\nfor doc in docs:\n    entities += len(doc.ents)\nprint(f\"DEV docs: {len(docs)} with {entities} entities\")",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "TRAIN docs: 17982 with 42228 entities\nDEV docs: 3596 with 8447 entities\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00015-31aa7384-e2c0-4db2-b720-bc8d7314e443",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "79c137b6",
    "execution_start": 1635724038829,
    "execution_millis": 53058122,
    "allow_embed": "output",
    "deepnote_cell_type": "code"
   },
   "source": "# Train model\n!python -m spacy train ../config/config.cfg --verbose --output ../data/textcat_output --paths.train ../data/spacy_data/textcat_train.spacy --paths.dev ../data/spacy_data/textcat_valid.spacy",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "2021-10-31 23:47:20.347614: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2021-10-31 23:47:20.347659: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n\u001b[38;5;4mℹ Saving to output directory: ../data/textcat_output\u001b[0m\n[2021-10-31 23:47:22,570] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev']\n\u001b[38;5;4mℹ Using CPU\u001b[0m\n\u001b[1m\n=========================== Initializing pipeline ===========================\u001b[0m\n[2021-10-31 23:47:23,329] [INFO] Set up nlp object from config\n[2021-10-31 23:47:23,338] [DEBUG] Loading corpus from path: ../data/spacy_data/textcat_valid.spacy\n[2021-10-31 23:47:23,339] [DEBUG] Loading corpus from path: ../data/spacy_data/textcat_train.spacy\n[2021-10-31 23:47:23,339] [INFO] Pipeline: ['transformer', 'textcat']\n[2021-10-31 23:47:23,343] [INFO] Created vocabulary\n[2021-10-31 23:47:23,344] [INFO] Finished initializing nlp object\nSome weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n[2021-10-31 23:47:55,080] [INFO] Initialized pipeline components: ['transformer', 'textcat']\n\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n\u001b[1m\n============================= Training pipeline =============================\u001b[0m\n[2021-10-31 23:47:55,091] [DEBUG] Loading corpus from path: ../data/spacy_data/textcat_valid.spacy\n[2021-10-31 23:47:55,092] [DEBUG] Loading corpus from path: ../data/spacy_data/textcat_train.spacy\n[2021-10-31 23:47:55,102] [DEBUG] Removed existing output directory: ../data/textcat_output/model-last\n\u001b[38;5;4mℹ Pipeline: ['transformer', 'textcat']\u001b[0m\n\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\nE    #       LOSS TRANS...  LOSS TEXTCAT  CATS_SCORE  SCORE \n---  ------  -------------  ------------  ----------  ------\n  0       0           0.00          2.60        0.00    0.00\n  0     200           0.00         63.25        0.00    0.00\n  1     400           0.17         58.71       29.87    0.30\n  1     600           0.60         50.54       41.98    0.42\n  1     800           0.61         52.42       49.28    0.49\n  2    1000           0.43         36.06       54.52    0.55\n  3    1200           1.20         42.47       55.77    0.56\n  3    1400           0.74         29.91       56.33    0.56\n  3    1600           0.70         28.39       57.41    0.57\n  4    1800           0.67         26.72       57.95    0.58\n  5    2000           1.01         29.96       59.06    0.59\n  5    2200           0.50         19.50       56.35    0.56\n  6    2400           0.63         25.54       62.61    0.63\n  6    2600           0.59         18.67       61.25    0.61\n  7    2800           0.78         23.83       60.90    0.61\n  7    3000           0.55         10.46       63.08    0.63\n  8    3200           0.59         14.70       61.78    0.62\n  8    3400           0.45          7.90       62.03    0.62\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "  9    3600           0.62         15.53       62.25    0.62\n  9    3800           0.42          7.37       63.12    0.63\n 10    4000           0.65          9.39       62.32    0.62\n 10    4200           0.37          8.03       61.73    0.62\n 11    4400           0.43          7.53       61.15    0.61\n 11    4600           0.46          7.06       62.89    0.63\n^C\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "The training time for each epoch is quite long due to the large size of the data and limited CPU on deepnote. This also shows the accuracy of the best epoch of the model, which has a accuracy score of 0.63.",
   "metadata": {
    "tags": [],
    "cell_id": "00019-a55189ee-c60a-4309-a0ab-5e44f64dd902",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Verification\n\nAfter training the model, I chose model of the best performing epoch and run the model on sample text.",
   "metadata": {
    "tags": [],
    "cell_id": "00020-5f36239c-5b1a-4db9-b316-fc4c5bb6d968",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00017-febb3711-5c4b-4f8d-b25d-0a573e97de1a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "118c4971",
    "execution_start": 1635777160800,
    "execution_millis": 1999,
    "deepnote_cell_type": "code"
   },
   "source": "# Verify model\nnlp_model = spacy.load(\"../data/textcat_output/model-best\")\ntest_text = test_data.OriginalTweet.tolist()\ntest_cats = test_data.Sentiment.tolist()\ndoc_test = nlp_model(test_text[20])\nprint(\"Text: \"+ test_text[20])\nprint(\"Orig Cat: \"+ test_cats[20])\nprint(\" Predicted Cats:\") \nprint(doc_test.cats)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Text: Widespread ramifications of the COVID-19 crisis have created a major demand for food assistance in our State. Help the @MDFoodBank with a donation to make sure no families have to go hungry during these challenging times.  #marylandcoronavirus\nOrig Cat: Negative\n Predicted Cats:\n{'extremely_positive': 0.0014480953104794025, 'extremely_negative': 0.24643553793430328, 'positive': 6.389307964127511e-05, 'negative': 0.6957257986068726, 'neutral': 0.056326642632484436}\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Pre-trained BERT Model\nNow, we train the model with pre-trained BERT.",
   "metadata": {
    "tags": [],
    "cell_id": "00022-d5846282-6425-4764-9b58-8ff1840d7c54",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00024-c10ebbd4-2dda-43da-b104-0ff38795d830",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "94f4442a",
    "execution_start": 1635855117430,
    "execution_millis": 398,
    "allow_embed": "code",
    "deepnote_cell_type": "code"
   },
   "source": "# Covert the train and test dataframes to .spacy files for training\n\n# Preprocess the dataframes for train data\ntrain_data_roberta, train_docs = preprocess(trainDF,\"en_core_web_trf\")\n# Save data and docs in a binary file to disc\ndoc_bin = DocBin(docs=train_docs)\ndoc_bin.to_disk(\"/work/data/spacy_data/textcat_roberta_train.spacy\")\n\n# Preprocess the dataframes for test data\ntest_data_roberta, test_docs = preprocess(testDF,\"en_core_web_trf\")\n# Save data and docs in a binary file to disc\ndoc_bin = DocBin(docs=test_docs)\ndoc_bin.to_disk(\"/work/data/spacy_data/textcat_roberta_valid.spacy\")",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'preprocess' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-240652f98f63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Preprocess the dataframes for train data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_data_roberta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainDF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"en_core_web_trf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Save data and docs in a binary file to disc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdoc_bin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDocBin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocess' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Model training\n\nI trained the same model but used the pre-trained BERT model with RoBERTa-based pipeline from `spacy-transfomer` package. I trained the model for 10 epochs using accuracy as the loss function and `adam` as the optimizer.",
   "metadata": {
    "tags": [],
    "cell_id": "00025-175c4b2d-e4d7-45a2-9bab-5c4b082e7e38",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00022-22cc3b36-3bee-4831-a8ae-1e527f3183f6",
    "allow_embed": "output",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "74af9826",
    "execution_start": 1635808162338,
    "execution_millis": 27887801,
    "deepnote_cell_type": "code"
   },
   "source": "# Train model\n!python -m spacy train ../config/config_bert.cfg --verbose --output ../data/textcat_roberta_output --paths.train ../data/spacy_data/textcat_roberta_train.spacy --paths.dev ../data/spacy_data/textcat_roberta_valid.spacy",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "2021-11-01 23:09:24.167894: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2021-11-01 23:09:24.167934: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n\u001b[38;5;4mℹ Saving to output directory: ../data/textcat_roberta_output\u001b[0m\n[2021-11-01 23:09:27,289] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev']\n\u001b[38;5;4mℹ Using CPU\u001b[0m\n\u001b[1m\n=========================== Initializing pipeline ===========================\u001b[0m\n[2021-11-01 23:09:28,160] [INFO] Set up nlp object from config\n[2021-11-01 23:09:28,170] [DEBUG] Loading corpus from path: ../data/spacy_data/textcat_roberta_valid.spacy\n[2021-11-01 23:09:28,170] [DEBUG] Loading corpus from path: ../data/spacy_data/textcat_roberta_train.spacy\n[2021-11-01 23:09:28,171] [INFO] Pipeline: ['transformer', 'textcat']\n[2021-11-01 23:09:28,175] [INFO] Created vocabulary\n[2021-11-01 23:09:28,175] [INFO] Finished initializing nlp object\nDownloading: 100%|███████████████████████████| 29.0/29.0 [00:00<00:00, 49.5kB/s]\nDownloading: 100%|█████████████████████████████| 570/570 [00:00<00:00, 1.07MB/s]\nDownloading: 100%|███████████████████████████| 213k/213k [00:00<00:00, 41.7MB/s]\nDownloading: 100%|███████████████████████████| 436k/436k [00:00<00:00, 43.0MB/s]\nDownloading: 100%|███████████████████████████| 436M/436M [00:06<00:00, 67.8MB/s]\nSome weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n[2021-11-01 23:10:03,978] [INFO] Initialized pipeline components: ['transformer', 'textcat']\n\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n\u001b[1m\n============================= Training pipeline =============================\u001b[0m\n[2021-11-01 23:10:03,992] [DEBUG] Loading corpus from path: ../data/spacy_data/textcat_roberta_valid.spacy\n[2021-11-01 23:10:03,993] [DEBUG] Loading corpus from path: ../data/spacy_data/textcat_roberta_train.spacy\n\u001b[38;5;4mℹ Pipeline: ['transformer', 'textcat']\u001b[0m\n\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\nE    #       LOSS TRANS...  LOSS TEXTCAT  CATS_SCORE  SCORE \n---  ------  -------------  ------------  ----------  ------\n  0       0           0.00          0.95        0.00    0.00\n  0     200           0.01         64.45        0.03    0.00\n  1     400           0.55         58.48       37.30    0.37\n  1     600           1.23         55.94       50.56    0.51\n  2     800           0.96         36.09       54.88    0.55\n  2    1000           1.57         32.82       55.99    0.56\n  3    1200           1.96         24.20       56.25    0.56\n  3    1400           1.57         25.00       58.42    0.58\n  4    1600           1.77         17.29       56.77    0.57\n  4    1800           2.17         30.06       59.27    0.59\n  5    2000           2.16         21.46       59.80    0.60\n  5    2200           1.75         12.77       60.46    0.60\n  6    2400           2.13         10.73       61.11    0.61\n  6    2600           1.28          8.27       60.69    0.61\n  7    2800           0.83          4.31       59.89    0.60\n  7    3000           0.84          9.68       61.09    0.61\n  8    3200           1.43          8.25       60.63    0.61\n  8    3400           1.01          4.51       60.67    0.61\n  9    3600           1.51          6.11       60.25    0.60\n  9    3800           1.83          5.99       60.10    0.60\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\r\n../data/textcat_roberta_output/model-last\r\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Verification\n\nAfter training the model, I chose the model of the best performing epoch and run the model on sample text.",
   "metadata": {
    "tags": [],
    "cell_id": "00027-fe471475-d64f-45f2-9595-82eff57097bb",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00028-7210cd7d-9172-40c1-a733-48bf5c1dc173",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "a52342a8",
    "execution_start": 1635851365468,
    "execution_millis": 7,
    "deepnote_cell_type": "code"
   },
   "source": "# Verify model\nnlp_model_bert = spacy.load(\"../data/textcat_roberta_output/model-best\")\ntest_text = test_data_roberta.OriginalTweet.tolist()\ntest_cats = test_data_roberta.Sentiment.tolist()\ndoc_test = nlp_model_bert(test_text[20])\nprint(\"Text: \"+ test_text[20])\nprint(\"Orig Cat: \"+ test_cats[20])\nprint(\" Predicted Cats:\") \nprint(doc_test.cats)",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'spacy' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2ac6faf8f59a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Verify model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnlp_model_bert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/textcat_roberta_output/model-best\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data_roberta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOriginalTweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_cats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data_roberta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdoc_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp_model_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spacy' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Testing out with validation set",
   "metadata": {
    "tags": [],
    "cell_id": "00029-d1328caa-e791-492a-8d80-6a602a4e52b7",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "I tested out the models using the validation set we created during the train test split process. I first loaded the differnt models and preprocessed the data.",
   "metadata": {
    "tags": [],
    "cell_id": "00030-7f7df511-f090-4296-9374-9df17207e1d3",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00030-30b0cbbf-8bcf-4c4a-a917-c2371330e43c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "266c421a",
    "execution_start": 1635858073346,
    "execution_millis": 60888,
    "deepnote_cell_type": "code"
   },
   "source": "# Covert the train and test dataframes to .spacy files for training\n\n# Preprocess the dataframes for valid data\nvalid_data, valid_docs = preprocess(validDF,\"en_core_web_sm\")\nvalid_data_roberta, valid_docs_roberta = preprocess(validDF,\"en_core_web_trf\")",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "('How easy do you think it is Piers Morgan to \\x91man up\\x92 &amp; \\x91get a grip\\x92 for those with anxiety, depression &amp;  no money????', 'Negative')\n100%|██████████| 900/900 [00:03<00:00, 274.12it/s]\n('How easy do you think it is Piers Morgan to \\x91man up\\x92 &amp; \\x91get a grip\\x92 for those with anxiety, depression &amp;  no money????', 'Negative')\n100%|██████████| 900/900 [00:54<00:00, 16.37it/s]\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "I then verified the model by choosing a random tweet to check the distribution of the different labels and the original category. ",
   "metadata": {
    "tags": [],
    "cell_id": "00032-030586d1-3513-48ce-9c7a-48b1ff9add08",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00030-fcc6e78e-8af5-474a-94f6-0cd55b1b2e6f",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "515b878f",
    "execution_start": 1635859851841,
    "execution_millis": 1687,
    "allow_embed": "code_output",
    "deepnote_cell_type": "code"
   },
   "source": "# Verify model for English model\nnlp_model = spacy.load(\"../data/textcat_output/model-best\")\nvalid_text = valid_data.OriginalTweet.tolist()\nvalid_cats = valid_data.Sentiment.tolist()\ndoc_valid = nlp_model(valid_text[50])\nprint(\"Text: \"+ valid_text[50])\nprint(\"Orig Cat: \"+ valid_cats[50])\nprint(\" Predicted Cats:\") \nprint(doc_valid.cats)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Text: Seriously, we are not running out of fresh produce. Also stop hoarding and making the prices go up and making it hard to shop for everyone else #coronavirusau #coronavirus #covid19australia\nOrig Cat: Negative\n Predicted Cats:\n{'extremely_positive': 0.00046054396079853177, 'extremely_negative': 0.18530161678791046, 'positive': 2.116534233209677e-05, 'negative': 0.8084510564804077, 'neutral': 0.005765631794929504}\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "I've done the same with the pre-trained BERT embedding model.",
   "metadata": {
    "tags": [],
    "cell_id": "00034-309f8a34-a90f-4bdc-a346-1dff1b09165e",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00030-c9b7d77e-a343-4eae-a0be-37dbd8386731",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "cfc3c72d",
    "execution_start": 1635859837049,
    "execution_millis": 1491,
    "allow_embed": "code_output",
    "deepnote_cell_type": "code"
   },
   "source": "nlp_model_bert = spacy.load(\"../data/textcat_roberta_output/model-best\")\ndoc_valid_bert = nlp_model_bert(valid_text[50])\nprint(\"Text: \"+ valid_text[50])\nprint(\"Orig Cat: \"+ valid_cats[50])\nprint(\" Predicted Cats:\") \nprint(doc_valid_bert.cats)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Text: Seriously, we are not running out of fresh produce. Also stop hoarding and making the prices go up and making it hard to shop for everyone else #coronavirusau #coronavirus #covid19australia\nOrig Cat: Negative\n Predicted Cats:\n{'extremely_positive': 0.0007743592723272741, 'extremely_negative': 0.047196418046951294, 'positive': 0.00013236790255177766, 'negative': 0.9406003952026367, 'neutral': 0.01129643153399229}\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=36980032-e74f-4047-828e-e2329ad1a610' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "97cb8250-e42f-4e53-b2e7-ba29d30a97fd",
  "deepnote_execution_queue": []
 }
}