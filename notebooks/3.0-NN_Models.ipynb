{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "## Neural Model\nThis is the code for the training the neural models.\n\n### Structure\n- Package Setup\n- Reorganize the data\n- Config Setup\n- Model Training\n- Verifidcation",
   "metadata": {
    "tags": [],
    "cell_id": "00000-26e23d31-a20e-48d2-9de2-2302c07ebf74",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Setup\nHere, I setup the packages and imported the data needed for model training.\n\n**Downloaded Packages**\n1. SpaCy English library\n2. SpaCy English Roberta-based library\n3. SpaCy Transformer\n\n**Imported Packages**\n1. Pandas\n2. SpaCy\n3. Scikit-learn\n4. re\n5. tqrm",
   "metadata": {
    "tags": [],
    "cell_id": "00001-d66f9fca-2e62-4fd6-ac81-059b63a63de8",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00000-3c091abe-1b72-42dc-8400-711bf752cc9f",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a0778b05",
    "execution_start": 1635777464809,
    "execution_millis": 24957,
    "deepnote_cell_type": "code"
   },
   "source": "# Installation of packages and pipelines\nimport sys\n# Import spaCy, load model\n!pip install spaCy \n!pip install spacy[transformers]\n!python -m spacy download en_core_web_sm\n!python -m spacy download en_core_web_trf\n",
   "outputs": [
    {
     "name": "stdout",
     "text": "2021-11-01 14:37:47.328034: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2021-11-01 14:37:47.328068: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\nCollecting en-core-web-trf==3.1.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.1.0/en_core_web_trf-3.1.0-py3-none-any.whl (460.2 MB)\n\u001b[K     |███████████████████████         | 331.7 MB 109.9 MB/s eta 0:00:02IOPub data rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_data_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n\u001b[K     |████████████████████████████████| 460.2 MB 7.1 kB/s \n\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from en-core-web-trf==3.1.0) (3.1.3)\nRequirement already satisfied: spacy-transformers<1.1.0,>=1.0.3 in /root/venv/lib/python3.7/site-packages (from en-core-web-trf==3.1.0) (1.0.6)\nRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (0.8.2)\nRequirement already satisfied: pathy>=0.3.5 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (0.6.0)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (2.0.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (3.0.8)\nRequirement already satisfied: setuptools in /root/venv/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (58.1.0)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (3.0.5)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (0.7.4)\nRequirement already satisfied: jinja2 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (3.0.2)\nRequirement already satisfied: typer<0.5.0,>=0.3.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (0.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (4.62.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (2.4.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (2.0.6)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (1.0.5)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (2.26.0)\nRequirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (3.10.0.2)\nRequirement already satisfied: packaging>=20.0 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (21.0)\nRequirement already satisfied: thinc<8.1.0,>=8.0.9 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (8.0.10)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (1.8.2)\nRequirement already satisfied: numpy>=1.15.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (1.19.5)\nRequirement already satisfied: zipp>=0.5 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (3.6.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (2.4.7)\nRequirement already satisfied: smart-open<6.0.0,>=5.0.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (5.2.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (1.26.7)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (2.0.7)\nRequirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (2021.10.8)\nRequirement already satisfied: idna<4,>=2.5 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (3.3)\nRequirement already satisfied: transformers<4.10.0,>=3.4.0 in /root/venv/lib/python3.7/site-packages (from spacy-transformers<1.1.0,>=1.0.3->en-core-web-trf==3.1.0) (4.9.2)\nRequirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /root/venv/lib/python3.7/site-packages (from spacy-transformers<1.1.0,>=1.0.3->en-core-web-trf==3.1.0) (0.8.3)\nRequirement already satisfied: torch>=1.5.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy-transformers<1.1.0,>=1.0.3->en-core-web-trf==3.1.0) (1.9.1)\nRequirement already satisfied: importlib-metadata in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from transformers<4.10.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.3->en-core-web-trf==3.1.0) (4.8.1)\nRequirement already satisfied: filelock in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from transformers<4.10.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.3->en-core-web-trf==3.1.0) (3.3.0)\nRequirement already satisfied: sacremoses in /root/venv/lib/python3.7/site-packages (from transformers<4.10.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.3->en-core-web-trf==3.1.0) (0.0.46)\nRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /root/venv/lib/python3.7/site-packages (from transformers<4.10.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.3->en-core-web-trf==3.1.0) (0.10.3)\nRequirement already satisfied: pyyaml>=5.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from transformers<4.10.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.3->en-core-web-trf==3.1.0) (5.4.1)\nRequirement already satisfied: huggingface-hub==0.0.12 in /root/venv/lib/python3.7/site-packages (from transformers<4.10.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.3->en-core-web-trf==3.1.0) (0.0.12)\nRequirement already satisfied: regex!=2019.12.17 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from transformers<4.10.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.3->en-core-web-trf==3.1.0) (2021.10.8)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (8.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-trf==3.1.0) (2.0.1)\nRequirement already satisfied: joblib in /shared-libs/python3.7/py/lib/python3.7/site-packages (from sacremoses->transformers<4.10.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.3->en-core-web-trf==3.1.0) (1.1.0)\nRequirement already satisfied: six in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from sacremoses->transformers<4.10.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.3->en-core-web-trf==3.1.0) (1.16.0)\nInstalling collected packages: en-core-web-trf\nSuccessfully installed en-core-web-trf-3.1.0\n\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_trf')\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00002-f5e4b070-fa4e-4427-b310-05085ab2dd09",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6165965a",
    "execution_start": 1635723922494,
    "execution_millis": 2712,
    "deepnote_cell_type": "code"
   },
   "source": "# Import packages\nimport spacy\nimport pandas as pd\nimport re\nfrom spacy.tokens import DocBin\nfrom tqdm import tqdm",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "I imported the data here.",
   "metadata": {
    "tags": [],
    "cell_id": "00004-d8b4a127-20ac-4e9d-8d07-6dba96208bb0",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00003-51c1b8f2-8900-4b74-81d1-291892f9206c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "162d9b1c",
    "execution_start": 1635723925209,
    "execution_millis": 197,
    "deepnote_cell_type": "code"
   },
   "source": "# Import dataset and pandas\nraw_trainDF = pd.read_csv(\"/work/data/coronavirus_tweet_raw/Corona_NLP_train.csv\")\nraw_testDF = pd.read_csv(\"/work/data/coronavirus_tweet_raw/Corona_NLP_test.csv\")\nraw_trainDF.head()",
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 3,
     "data": {
      "application/vnd.deepnote.dataframe.v2+json": {
       "row_count": 5,
       "column_count": 6,
       "columns": [
        {
         "name": "UserName",
         "dtype": "int64",
         "stats": {
          "unique_count": 5,
          "nan_count": 0,
          "min": "3799",
          "max": "3803",
          "histogram": [
           {
            "bin_start": 3799,
            "bin_end": 3799.4,
            "count": 1
           },
           {
            "bin_start": 3799.4,
            "bin_end": 3799.8,
            "count": 0
           },
           {
            "bin_start": 3799.8,
            "bin_end": 3800.2,
            "count": 1
           },
           {
            "bin_start": 3800.2,
            "bin_end": 3800.6,
            "count": 0
           },
           {
            "bin_start": 3800.6,
            "bin_end": 3801,
            "count": 0
           },
           {
            "bin_start": 3801,
            "bin_end": 3801.4,
            "count": 1
           },
           {
            "bin_start": 3801.4,
            "bin_end": 3801.8,
            "count": 0
           },
           {
            "bin_start": 3801.8,
            "bin_end": 3802.2,
            "count": 1
           },
           {
            "bin_start": 3802.2,
            "bin_end": 3802.6,
            "count": 0
           },
           {
            "bin_start": 3802.6,
            "bin_end": 3803,
            "count": 1
           }
          ]
         }
        },
        {
         "name": "ScreenName",
         "dtype": "int64",
         "stats": {
          "unique_count": 5,
          "nan_count": 0,
          "min": "48751",
          "max": "48755",
          "histogram": [
           {
            "bin_start": 48751,
            "bin_end": 48751.4,
            "count": 1
           },
           {
            "bin_start": 48751.4,
            "bin_end": 48751.8,
            "count": 0
           },
           {
            "bin_start": 48751.8,
            "bin_end": 48752.2,
            "count": 1
           },
           {
            "bin_start": 48752.2,
            "bin_end": 48752.6,
            "count": 0
           },
           {
            "bin_start": 48752.6,
            "bin_end": 48753,
            "count": 0
           },
           {
            "bin_start": 48753,
            "bin_end": 48753.4,
            "count": 1
           },
           {
            "bin_start": 48753.4,
            "bin_end": 48753.8,
            "count": 0
           },
           {
            "bin_start": 48753.8,
            "bin_end": 48754.2,
            "count": 1
           },
           {
            "bin_start": 48754.2,
            "bin_end": 48754.6,
            "count": 0
           },
           {
            "bin_start": 48754.6,
            "bin_end": 48755,
            "count": 1
           }
          ]
         }
        },
        {
         "name": "Location",
         "dtype": "object",
         "stats": {
          "unique_count": 3,
          "nan_count": 2,
          "categories": [
           {
            "name": "London",
            "count": 1
           },
           {
            "name": "2 others",
            "count": 2
           },
           {
            "name": "Missing",
            "count": 2
           }
          ]
         }
        },
        {
         "name": "TweetAt",
         "dtype": "object",
         "stats": {
          "unique_count": 1,
          "nan_count": 0,
          "categories": [
           {
            "name": "16-03-2020",
            "count": 5
           }
          ]
         }
        },
        {
         "name": "OriginalTweet",
         "dtype": "object",
         "stats": {
          "unique_count": 5,
          "nan_count": 0,
          "categories": [
           {
            "name": "@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/iFz9FAn2Pa and https://t.co/xX6ghGFzCC and https://t.co/I2NlzdxNo8",
            "count": 1
           },
           {
            "name": "advice Talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist GP set up online shopping accounts if poss adequate supplies of regular meds but not over order",
            "count": 1
           },
           {
            "name": "3 others",
            "count": 3
           }
          ]
         }
        },
        {
         "name": "Sentiment",
         "dtype": "object",
         "stats": {
          "unique_count": 3,
          "nan_count": 0,
          "categories": [
           {
            "name": "Positive",
            "count": 3
           },
           {
            "name": "Neutral",
            "count": 1
           },
           {
            "name": "Extremely Negative",
            "count": 1
           }
          ]
         }
        },
        {
         "name": "_deepnote_index_column",
         "dtype": "int64"
        }
       ],
       "rows_top": [
        {
         "UserName": 3799,
         "ScreenName": 48751,
         "Location": "London",
         "TweetAt": "16-03-2020",
         "OriginalTweet": "@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/iFz9FAn2Pa and https://t.co/xX6ghGFzCC and https://t.c…",
         "Sentiment": "Neutral",
         "_deepnote_index_column": 0
        },
        {
         "UserName": 3800,
         "ScreenName": 48752,
         "Location": "UK",
         "TweetAt": "16-03-2020",
         "OriginalTweet": "advice Talk to your neighbours family to exchange phone numbers create contact list with phone numb…",
         "Sentiment": "Positive",
         "_deepnote_index_column": 1
        },
        {
         "UserName": 3801,
         "ScreenName": 48753,
         "Location": "Vagabonds",
         "TweetAt": "16-03-2020",
         "OriginalTweet": "Coronavirus Australia: Woolworths to give elderly, disabled dedicated shopping hours amid COVID-19 …",
         "Sentiment": "Positive",
         "_deepnote_index_column": 2
        },
        {
         "UserName": 3802,
         "ScreenName": 48754,
         "Location": "nan",
         "TweetAt": "16-03-2020",
         "OriginalTweet": "My food stock is not the only one which is empty...\r\r\n\r\r\nPLEASE, don't panic, THERE WILL BE ENOUGH …",
         "Sentiment": "Positive",
         "_deepnote_index_column": 3
        },
        {
         "UserName": 3803,
         "ScreenName": 48755,
         "Location": "nan",
         "TweetAt": "16-03-2020",
         "OriginalTweet": "Me, ready to go at supermarket during the #COVID19 outbreak.\r\r\n\r\r\nNot because I'm paranoid, but bec…",
         "Sentiment": "Extremely Negative",
         "_deepnote_index_column": 4
        }
       ],
       "rows_bottom": null
      },
      "text/plain": "   UserName  ScreenName   Location     TweetAt  \\\n0      3799       48751     London  16-03-2020   \n1      3800       48752         UK  16-03-2020   \n2      3801       48753  Vagabonds  16-03-2020   \n3      3802       48754        NaN  16-03-2020   \n4      3803       48755        NaN  16-03-2020   \n\n                                       OriginalTweet           Sentiment  \n0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n1  advice Talk to your neighbours family to excha...            Positive  \n2  Coronavirus Australia: Woolworths to give elde...            Positive  \n3  My food stock is not the only one which is emp...            Positive  \n4  Me, ready to go at supermarket during the #COV...  Extremely Negative  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserName</th>\n      <th>ScreenName</th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3799</td>\n      <td>48751</td>\n      <td>London</td>\n      <td>16-03-2020</td>\n      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3800</td>\n      <td>48752</td>\n      <td>UK</td>\n      <td>16-03-2020</td>\n      <td>advice Talk to your neighbours family to excha...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3801</td>\n      <td>48753</td>\n      <td>Vagabonds</td>\n      <td>16-03-2020</td>\n      <td>Coronavirus Australia: Woolworths to give elde...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3802</td>\n      <td>48754</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>My food stock is not the only one which is emp...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3803</td>\n      <td>48755</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>Me, ready to go at supermarket during the #COV...</td>\n      <td>Extremely Negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00003-bdbae09b-0008-41d5-bba7-7ac199683b6b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "1734b6f0",
    "execution_start": 1635723925405,
    "execution_millis": 3,
    "deepnote_cell_type": "code"
   },
   "source": "# Copy the values of the data for further uses\ntrainDF = raw_trainDF\ntestDF = raw_testDF",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Reorganize the data\nDue to the observation during the EDA process, I decided to concatenate the dataset and resplit them.",
   "metadata": {
    "tags": [],
    "cell_id": "00005-e3f66c0c-1cc3-42b2-ad18-aeae2136dfae",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00005-e46ad648-9378-4f62-ad84-9a8473ded0b5",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "aab1244e",
    "execution_start": 1635723925410,
    "execution_millis": 504,
    "deepnote_cell_type": "code"
   },
   "source": "# Train test split\nfrom sklearn.model_selection import train_test_split\n\n# Concat the two datasets and split them\nallDF = pd.concat((trainDF, testDF), ignore_index=True)\n\n# Sample dataset due to the large size\nallDF = allDF.sample(frac=0.5).reset_index(drop=True)\n\n# Split the train, test, validation set\ntrainDF, testDF = train_test_split(allDF, test_size = 0.2)\ntestDF, validDF = train_test_split(testDF, test_size = 0.2)\n\n# Print values\nprint(\"Train:\",len(trainDF), \"Test:\", len(testDF),\"Valid:\", len(validDF))",
   "outputs": [
    {
     "name": "stdout",
     "text": "Train: 17982 Test: 3596 Valid: 900\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Preprocess the data\n\nI then preprocess the data by removing urls, conduct one-hot encoding for the categories, and add the data into SpaCy pipelines. Finally, I saved the data into binary `.spacy` for training. In addition, I separated the pretraining with just normal English pipeline and RoBERTa-based pipeline.",
   "metadata": {
    "tags": [],
    "cell_id": "00009-c9225b40-c7e0-4964-9bbc-02cea72bc5db",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00002-866ffbd9-556b-46db-864d-13b591162eb6",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d37de714",
    "execution_start": 1635777546420,
    "execution_millis": 0,
    "allow_embed": "code",
    "deepnote_cell_type": "code"
   },
   "source": "def remove_url(text): \n    '''\n    Remove urls from text.\n    ---\n    Input:\n    text (str): a sentence\n\n    Output:\n    parsed_text (str): text that has url removed\n    '''\n\n    # Use regrex to parse urls from the text\n    parsed_text = re.sub(r\"\\S*https?:\\S*\", \"\", text, flags=re.MULTILINE)\n    return parsed_text\n\ndef preprocess(df, embed):\n    '''\n    Preprocess the dataframe into spacy pipeline for later classification\n    ---\n    Input:\n    df (DataFrame): Pandas dataframe containing the raw text and outputs.\n    embed (str): Name of pipeline embedding used\n\n    Output:\n    df (DataFrame): Preprocessed input dataframe\n    docs (doc): SpaCy doc object that stores text data along with classification\n    '''\n\n    # Remove urls from text\n    df.OriginalTweet = df.OriginalTweet.apply(remove_url)\n\n    # Store the data into tuples\n    data = tuple(zip(df.OriginalTweet.tolist(), df.Sentiment.tolist())) \n    \n    # Load English library from SpaCy\n    nlp=spacy.load(embed)\n    print(data[0])\n\n    # Storage for docs\n    docs = []\n\n    # One-hot encoding for the classifications\n    for doc, label in tqdm(nlp.pipe(data, as_tuples=True), total = len(data)):\n        \n        if label=='Extremely Positive':\n            doc.cats['extremely_positive'] = 1\n            doc.cats['extremely_negative'] = 0\n            doc.cats['positive'] = 0\n            doc.cats['negative'] = 0\n            doc.cats['neutral']  = 0\n        elif label=='Positive':\n            doc.cats['extremely_positive'] = 0\n            doc.cats['extremely_negative'] = 1\n            doc.cats['positive'] = 0\n            doc.cats['negative'] = 0\n            doc.cats['neutral']  = 0\n        elif label=='Neutral':\n            doc.cats['extremely_positive'] = 0\n            doc.cats['extremely_negative'] = 0\n            doc.cats['positive'] = 0\n            doc.cats['negative'] = 0\n            doc.cats['neutral']  = 1\n        elif label=='Negative':\n            doc.cats['extremely_positive'] = 0\n            doc.cats['extremely_negative'] = 0\n            doc.cats['positive'] = 0\n            doc.cats['negative'] = 1\n            doc.cats['neutral']  = 0\n        else:\n            doc.cats['extremely_positive'] = 0\n            doc.cats['extremely_negative'] = 1\n            doc.cats['positive'] = 0\n            doc.cats['negative'] = 0\n            doc.cats['neutral']  = 0\n        # print(doc.cats)\n        \n        docs.append(doc)\n    return df, docs\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Config setup\n\nI setup the training config using SpaCy's [quickstart function](https://spacy.io/usage/training#quickstart). This creates a `base_config.cfg` that can be filled into `config.cfg`. This `config` file can then be used to train the model using command line operations. The setup for the quickstart function is shown in the image below.",
   "metadata": {
    "tags": [],
    "cell_id": "00012-97285783-fbfc-470d-afb3-74d457c0a855",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "![config_setup](../images/config_setup.png)",
   "metadata": {
    "tags": [],
    "cell_id": "00013-71f8fb1e-8669-44c3-9572-468d2be998bf",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00010-649bbc18-2053-47d5-a689-838939ad2569",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ff8f9ebb",
    "execution_start": 1635724016177,
    "execution_millis": 9375,
    "allow_embed": "code_output",
    "deepnote_cell_type": "code"
   },
   "source": "# Initialize config files from base_config\n!python -m spacy init fill-config ../config/base_config.cfg ../config/config.cfg ",
   "outputs": [
    {
     "name": "stdout",
     "text": "2021-10-31 23:46:58.031841: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2021-10-31 23:46:58.031884: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n\u001b[38;5;2m✔ Saved config\u001b[0m\n../config/config.cfg\nYou can now add your data and train your pipeline:\npython -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Debug config\n!python -m spacy debug data ../config/config.cfg",
   "metadata": {
    "tags": [],
    "cell_id": "00016-8d9aae97-6594-498a-84ce-e5e3a9215870",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6dbb2d4e",
    "execution_start": 1635724025573,
    "execution_millis": 5086,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "2021-10-31 23:47:07.092715: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2021-10-31 23:47:07.092753: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n\u001b[1m\n============================ Data file validation ============================\u001b[0m\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/spacy/__main__.py\", line 4, in <module>\n    setup_cli()\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/spacy/cli/_util.py\", line 69, in setup_cli\n    command(prog_name=COMMAND)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/click/core.py\", line 1128, in __call__\n    return self.main(*args, **kwargs)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/click/core.py\", line 1053, in main\n    rv = self.invoke(ctx)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/click/core.py\", line 1659, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/click/core.py\", line 1659, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/click/core.py\", line 1395, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/click/core.py\", line 754, in invoke\n    return __callback(*args, **kwargs)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/typer/main.py\", line 500, in wrapper\n    return callback(**use_params)  # type: ignore\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/spacy/cli/debug_data.py\", line 71, in debug_data_cli\n    silent=False,\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/spacy/cli/debug_data.py\", line 103, in debug_data\n    train_corpus, dev_corpus = resolve_dot_names(config, dot_names)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/spacy/util.py\", line 500, in resolve_dot_names\n    result = registry.resolve(config[section])\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/thinc/config.py\", line 730, in resolve\n    config, schema=schema, overrides=overrides, validate=validate, resolve=True\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/thinc/config.py\", line 779, in _make\n    config, schema, validate=validate, overrides=overrides, resolve=resolve\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/thinc/config.py\", line 850, in _fill\n    getter_result = getter(*args, **kwargs)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/spacy/training/corpus.py\", line 31, in create_docbin_reader\n    raise ValueError(Errors.E913)\nValueError: [E913] Corpus path can't be None. Maybe you forgot to define it in your config.cfg or override it on the CLI?\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## SpaCy's English Model\nI first train the model with normal English pipeline from spaCy.",
   "metadata": {
    "tags": [],
    "cell_id": "00011-3df34364-3cfe-4853-8104-a8d925abe713",
    "deepnote_cell_type": "markdown"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00009-605760bf-f627-4873-a2c6-22e477c4afa1",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c72c9fee",
    "execution_start": 1635723925928,
    "execution_millis": 90229,
    "allow_embed": "code",
    "deepnote_cell_type": "code"
   },
   "source": "# Covert the train and test dataframes to .spacy files for training\n\n# Preprocess the dataframes for train data\ntrain_data, train_docs = preprocess(trainDF,\"en_core_web_sm\")\n# Save data and docs in a binary file to disc\ndoc_bin = DocBin(docs=train_docs)\ndoc_bin.to_disk(\"/work/data/spacy_data/textcat_train.spacy\")\n\n# Preprocess the dataframes for test data\ntest_data, test_docs = preprocess(testDF,\"en_core_web_sm\")\n# Save data and docs in a binary file to disc\ndoc_bin = DocBin(docs=test_docs)\ndoc_bin.to_disk(\"/work/data/spacy_data/textcat_valid.spacy\")",
   "outputs": [
    {
     "name": "stdout",
     "text": "('I work in a supermarket. I understand why social distancing &amp; self isolating is so important right now. However. I\\x92m still going into work &amp; risking my own exposure ? HOW the hell do I help myself &amp; others ??! Confused #Covid_19', 'Extremely Negative')\n100%|██████████| 17982/17982 [01:01<00:00, 290.76it/s]\n('Dampf, store manager of the Paramus @StewLeonards: \"We don\\x92t have a lot of paper goods ... soap ... cleaning supplies. That\\x92s not what our niche is. We\\x92re a fresh food market: 80% of our items are fresh food. Only 20% is grocery.\" / #COVID19 #coronavirus ', 'Positive')\n100%|██████████| 3596/3596 [00:13<00:00, 263.99it/s]\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Model training\n\nI first verify the `.spacy` files before running the command line operation for training the model. The model is an ensemble of a tok2vec model that uses attention under the transformer architecture combined with a linear bag-of-words model. I trained the model for 11 epochs using accuracy as the loss function and `adam` as the optimizer.",
   "metadata": {
    "tags": [],
    "cell_id": "00016-5f3273ad-079a-4243-9716-763e6e3760e8",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "source": "# View the entities in the train and test docs\ntrain_loc = \"/work/data/spacy_data/textcat_train.spacy\"\ndev_loc = \"/work/data/spacy_data/textcat_valid.spacy\"\n\n# Load library and train data\nnlp = spacy.load('en_core_web_sm')\ndoc_bin = DocBin().from_disk(train_loc)\ndocs = list(doc_bin.get_docs(nlp.vocab))\nentities = 0\n\n# Iterate through the docs\nfor doc in docs:\n    entities += len(doc.ents)\nprint(f\"TRAIN docs: {len(docs)} with {entities} entities\")\n\n# Load library and test data\ndoc_bin = DocBin().from_disk(dev_loc)\ndocs = list(doc_bin.get_docs(nlp.vocab))\nentities = 0\n\n# Iterate through the docs\nfor doc in docs:\n    entities += len(doc.ents)\nprint(f\"DEV docs: {len(docs)} with {entities} entities\")",
   "metadata": {
    "tags": [],
    "cell_id": "00016-aa33cfa6-8a07-45fc-9c58-02f5648f81c6",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ab38c155",
    "execution_start": 1635724030665,
    "execution_millis": 8144,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "TRAIN docs: 17982 with 42228 entities\nDEV docs: 3596 with 8447 entities\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Train model\n!python -m spacy train ../config/config.cfg --verbose --output ../data/textcat_output --paths.train ../data/spacy_data/textcat_train.spacy --paths.dev ../data/spacy_data/textcat_valid.spacy",
   "metadata": {
    "tags": [],
    "cell_id": "00015-31aa7384-e2c0-4db2-b720-bc8d7314e443",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "79c137b6",
    "execution_start": 1635724038829,
    "execution_millis": 53058122,
    "allow_embed": "code",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "2021-10-31 23:47:20.347614: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2021-10-31 23:47:20.347659: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n\u001b[38;5;4mℹ Saving to output directory: ../data/textcat_output\u001b[0m\n[2021-10-31 23:47:22,570] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev']\n\u001b[38;5;4mℹ Using CPU\u001b[0m\n\u001b[1m\n=========================== Initializing pipeline ===========================\u001b[0m\n[2021-10-31 23:47:23,329] [INFO] Set up nlp object from config\n[2021-10-31 23:47:23,338] [DEBUG] Loading corpus from path: ../data/spacy_data/textcat_valid.spacy\n[2021-10-31 23:47:23,339] [DEBUG] Loading corpus from path: ../data/spacy_data/textcat_train.spacy\n[2021-10-31 23:47:23,339] [INFO] Pipeline: ['transformer', 'textcat']\n[2021-10-31 23:47:23,343] [INFO] Created vocabulary\n[2021-10-31 23:47:23,344] [INFO] Finished initializing nlp object\nSome weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n[2021-10-31 23:47:55,080] [INFO] Initialized pipeline components: ['transformer', 'textcat']\n\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n\u001b[1m\n============================= Training pipeline =============================\u001b[0m\n[2021-10-31 23:47:55,091] [DEBUG] Loading corpus from path: ../data/spacy_data/textcat_valid.spacy\n[2021-10-31 23:47:55,092] [DEBUG] Loading corpus from path: ../data/spacy_data/textcat_train.spacy\n[2021-10-31 23:47:55,102] [DEBUG] Removed existing output directory: ../data/textcat_output/model-last\n\u001b[38;5;4mℹ Pipeline: ['transformer', 'textcat']\u001b[0m\n\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\nE    #       LOSS TRANS...  LOSS TEXTCAT  CATS_SCORE  SCORE \n---  ------  -------------  ------------  ----------  ------\n  0       0           0.00          2.60        0.00    0.00\n  0     200           0.00         63.25        0.00    0.00\n  1     400           0.17         58.71       29.87    0.30\n  1     600           0.60         50.54       41.98    0.42\n  1     800           0.61         52.42       49.28    0.49\n  2    1000           0.43         36.06       54.52    0.55\n  3    1200           1.20         42.47       55.77    0.56\n  3    1400           0.74         29.91       56.33    0.56\n  3    1600           0.70         28.39       57.41    0.57\n  4    1800           0.67         26.72       57.95    0.58\n  5    2000           1.01         29.96       59.06    0.59\n  5    2200           0.50         19.50       56.35    0.56\n  6    2400           0.63         25.54       62.61    0.63\n  6    2600           0.59         18.67       61.25    0.61\n  7    2800           0.78         23.83       60.90    0.61\n  7    3000           0.55         10.46       63.08    0.63\n  8    3200           0.59         14.70       61.78    0.62\n  8    3400           0.45          7.90       62.03    0.62\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "  9    3600           0.62         15.53       62.25    0.62\n  9    3800           0.42          7.37       63.12    0.63\n 10    4000           0.65          9.39       62.32    0.62\n 10    4200           0.37          8.03       61.73    0.62\n 11    4400           0.43          7.53       61.15    0.61\n 11    4600           0.46          7.06       62.89    0.63\n^C\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "The training time for each epoch is quite long due to the large size of the data and limited CPU on deepnote. This also shows the accuracy of the best epoch of the model, which has a accuracy score of 0.63.",
   "metadata": {
    "tags": [],
    "cell_id": "00019-a55189ee-c60a-4309-a0ab-5e44f64dd902",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Verification\n\nAfter training the model, I chose model of the best performing epoch and run the model on sample text.",
   "metadata": {
    "tags": [],
    "cell_id": "00020-5f36239c-5b1a-4db9-b316-fc4c5bb6d968",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "source": "# Verify model\nnlp_model = spacy.load(\"../data/textcat_output/model-best\")\ntest_text = test_data.OriginalTweet.tolist()\ntest_cats = test_data.Sentiment.tolist()\ndoc_test = nlp_model(test_text[20])\nprint(\"Text: \"+ test_text[20])\nprint(\"Orig Cat: \"+ test_cats[20])\nprint(\" Predicted Cats:\") \nprint(doc_test.cats)",
   "metadata": {
    "tags": [],
    "cell_id": "00017-febb3711-5c4b-4f8d-b25d-0a573e97de1a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "118c4971",
    "execution_start": 1635777160800,
    "execution_millis": 1999,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Text: Widespread ramifications of the COVID-19 crisis have created a major demand for food assistance in our State. Help the @MDFoodBank with a donation to make sure no families have to go hungry during these challenging times.  #marylandcoronavirus\nOrig Cat: Negative\n Predicted Cats:\n{'extremely_positive': 0.0014480953104794025, 'extremely_negative': 0.24643553793430328, 'positive': 6.389307964127511e-05, 'negative': 0.6957257986068726, 'neutral': 0.056326642632484436}\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## RoBERTa-based Model\nNow, we train the model using RoBERTa-based pipeline. ",
   "metadata": {
    "tags": [],
    "cell_id": "00022-d5846282-6425-4764-9b58-8ff1840d7c54",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "source": "# Covert the train and test dataframes to .spacy files for training\n\n# Preprocess the dataframes for train data\ntrain_data_roberta, train_docs = preprocess(trainDF,\"en_core_web_trf\")\n# Save data and docs in a binary file to disc\ndoc_bin = DocBin(docs=train_docs)\ndoc_bin.to_disk(\"/work/data/spacy_data/textcat_roberta_train.spacy\")\n\n# Preprocess the dataframes for test data\ntest_data_roberta, test_docs = preprocess(testDF,\"en_core_web_trf\")\n# Save data and docs in a binary file to disc\ndoc_bin = DocBin(docs=test_docs)\ndoc_bin.to_disk(\"/work/data/spacy_data/textcat_roberta_valid.spacy\")",
   "metadata": {
    "tags": [],
    "cell_id": "00024-c10ebbd4-2dda-43da-b104-0ff38795d830",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "94f4442a",
    "execution_start": 1635777554695,
    "execution_millis": 2275,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "('I work in a supermarket. I understand why social distancing &amp; self isolating is so important right now. However. I\\x92m still going into work &amp; risking my own exposure ? HOW the hell do I help myself &amp; others ??! Confused #Covid_19', 'Extremely Negative')\n100%|██████████| 17982/17982 [27:24<00:00, 10.94it/s]\n",
     "output_type": "stream"
    },
    {
     "output_type": "error",
     "ename": "KernelInterrupted",
     "evalue": "Execution interrupted by the Jupyter kernel.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKernelInterrupted\u001b[0m: Execution interrupted by the Jupyter kernel."
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Model training\n\nI trained the same model but used the RoBERTa-based pipeline from `spacy-transfomer`. I trained the model for 10 epochs using accuracy as the loss function and `adam` as the optimizer.",
   "metadata": {
    "tags": [],
    "cell_id": "00025-175c4b2d-e4d7-45a2-9bab-5c4b082e7e38",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "source": "# Train model\n!python -m spacy train ../config/config.cfg --verbose --output ../data/textcat_roberta_output --paths.train ../data/spacy_data/textcat_roberta_train.spacy --paths.dev ../data/spacy_data/textcat_roberta_valid.spacy",
   "metadata": {
    "tags": [],
    "cell_id": "00022-22cc3b36-3bee-4831-a8ae-1e527f3183f6",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Verification\n\nAfter training the model, I chose the model of the best performing epoch and run the model on sample text.",
   "metadata": {
    "tags": [],
    "cell_id": "00027-fe471475-d64f-45f2-9595-82eff57097bb",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "source": "# Verify model\nnlp_model = spacy.load(\"../data/textcat_roberta_output/model-best\")\ntest_text = test_data_roberta.OriginalTweet.tolist()\ntest_cats = test_data_roberta.Sentiment.tolist()\ndoc_test = nlp_model(test_text[20])\nprint(\"Text: \"+ test_text[20])\nprint(\"Orig Cat: \"+ test_cats[20])\nprint(\" Predicted Cats:\") \nprint(doc_test.cats)",
   "metadata": {
    "tags": [],
    "cell_id": "00028-7210cd7d-9172-40c1-a733-48bf5c1dc173",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=36980032-e74f-4047-828e-e2329ad1a610' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "97cb8250-e42f-4e53-b2e7-ba29d30a97fd",
  "deepnote_execution_queue": []
 }
}